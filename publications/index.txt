1:"$Sreact.fragment"
2:I[3719,["17","static/chunks/17-9c04c9413a9f9f1f.js","874","static/chunks/874-6cc630662f3664af.js","862","static/chunks/862-15038af301665bb3.js","177","static/chunks/app/layout-a599ae3b83e56ca7.js"],"ThemeProvider"]
3:I[768,["17","static/chunks/17-9c04c9413a9f9f1f.js","874","static/chunks/874-6cc630662f3664af.js","862","static/chunks/862-15038af301665bb3.js","177","static/chunks/app/layout-a599ae3b83e56ca7.js"],"default"]
4:I[7555,[],""]
5:I[1295,[],""]
6:I[2548,["17","static/chunks/17-9c04c9413a9f9f1f.js","874","static/chunks/874-6cc630662f3664af.js","862","static/chunks/862-15038af301665bb3.js","177","static/chunks/app/layout-a599ae3b83e56ca7.js"],"default"]
8:I[9665,[],"MetadataBoundary"]
a:I[9665,[],"OutletBoundary"]
d:I[4911,[],"AsyncMetadataOutlet"]
f:I[9665,[],"ViewportBoundary"]
11:I[6614,[],""]
:HL["/_next/static/css/92b53c90e215dddf.css","style"]
0:{"P":null,"b":"nlG6K_sVfYNpsXnE0KN-m","p":"","c":["","publications",""],"i":false,"f":[[["",{"children":[["slug","publications","d"],{"children":["__PAGE__",{}]}]},"$undefined","$undefined",true],["",["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/92b53c90e215dddf.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","html",null,{"lang":"en","className":"scroll-smooth","suppressHydrationWarning":true,"children":[["$","head",null,{"children":[["$","link",null,{"rel":"icon","href":"/favicon.svg","type":"image/svg+xml"}],["$","link",null,{"rel":"dns-prefetch","href":"https://google-fonts.jialeliu.com"}],["$","link",null,{"rel":"preconnect","href":"https://google-fonts.jialeliu.com","crossOrigin":""}],["$","link",null,{"rel":"preload","as":"style","href":"https://google-fonts.jialeliu.com/css2?family=Inter:wght@300;400;500;600;700&family=Crimson+Text:ital,wght@0,400;0,600;1,400&display=swap"}],["$","link",null,{"rel":"stylesheet","id":"gfonts-css","href":"https://google-fonts.jialeliu.com/css2?family=Inter:wght@300;400;500;600;700&family=Crimson+Text:ital,wght@0,400;0,600;1,400&display=swap","media":"print"}],["$","script",null,{"dangerouslySetInnerHTML":{"__html":"\n              (function(){\n                var l = document.getElementById('gfonts-css');\n                if (!l) return;\n                if (l.media !== 'all') {\n                  l.addEventListener('load', function(){ try { l.media = 'all'; } catch(e){} });\n                }\n              })();\n            "}}],["$","noscript",null,{"children":["$","link",null,{"rel":"stylesheet","href":"https://google-fonts.jialeliu.com/css2?family=Inter:wght@300;400;500;600;700&family=Crimson+Text:ital,wght@0,400;0,600;1,400&display=swap"}]}],["$","script",null,{"dangerouslySetInnerHTML":{"__html":"\n              try {\n                const theme = localStorage.getItem('theme-storage');\n                const parsed = theme ? JSON.parse(theme) : null;\n                const setting = parsed?.state?.theme || 'system';\n                const prefersDark = typeof window !== 'undefined' && window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;\n                const effective = setting === 'dark' ? 'dark' : (setting === 'light' ? 'light' : (prefersDark ? 'dark' : 'light'));\n                var root = document.documentElement;\n                root.classList.add(effective);\n                root.setAttribute('data-theme', effective);\n              } catch (e) {\n                var root = document.documentElement;\n                root.classList.add('light');\n                root.setAttribute('data-theme', 'light');\n              }\n            "}}]]}],["$","body",null,{"className":"font-sans antialiased","children":["$","$L2",null,{"children":[["$","$L3",null,{"items":[{"title":"About","type":"page","target":"about","href":"/"},{"title":"Publications","type":"page","target":"publications","href":"/publications"},{"title":"Funding","type":"page","target":"funding","href":"/funding"},{"title":"Awards","type":"page","target":"awards","href":"/awards"},{"title":"Teaching","type":"page","target":"teaching","href":"/teaching"},{"title":"Blog","type":"page","target":"blog","href":"/blog"}],"siteTitle":"Slim","enableOnePageMode":false}],["$","main",null,{"className":"min-h-screen pt-16 lg:pt-20","children":["$","$L4",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":404}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],[]],"forbidden":"$undefined","unauthorized":"$undefined"}]}],["$","$L6",null,{"lastUpdated":"February 4, 2026"}]]}]}]]}]]}],{"children":[["slug","publications","d"],["$","$1","c",{"children":[null,["$","$L4",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":["__PAGE__",["$","$1","c",{"children":["$L7",["$","$L8",null,{"children":"$L9"}],null,["$","$La",null,{"children":["$Lb","$Lc",["$","$Ld",null,{"promise":"$@e"}]]}]]}],{},null,false]},null,false]},null,false],["$","$1","h",{"children":[null,["$","$1","salIxeEDbNBxeW_LB8fS9",{"children":[["$","$Lf",null,{"children":"$L10"}],null]}],null]}],false]],"m":"$undefined","G":["$11","$undefined"],"s":false,"S":true}
12:"$Sreact.suspense"
13:I[4911,[],"AsyncMetadata"]
15:I[6669,["17","static/chunks/17-9c04c9413a9f9f1f.js","178","static/chunks/178-595a94b9af1e67b5.js","748","static/chunks/748-b0753eeaf12cb586.js","182","static/chunks/app/%5Bslug%5D/page-8dd78c96a6c24afb.js"],"default"]
9:["$","$12",null,{"fallback":null,"children":["$","$L13",null,{"promise":"$@14"}]}]
16:T4a8,Recent advancements in artificial intelligence are revolutionizing healthcare. The development of AI models for predicting patient acuity in tele-triage shows promising potential for high-quality patient care and efficient healthcare systems. However, existing research has not explored how to achieve effective predictions using limited patient self-reported data. Therefore, we follow the computational design science approach to propose DAJoLoss, a novel dual-adapter architecture with a domain-based joint loss optimization method for fine-tuning large language models (LLMs). This computational artifact enables transfer learning from informative training-only data to improve prediction. Comprehensive evaluation results demonstrate that our artifact achieves at least a 5% improvement across all metrics compared to mainstream machine learning approaches in tele-triage research. This study not only provides insights into overcoming data availability limitations in tele-triage prediction but also contributes to information systems knowledge base on designing computational artifacts for optimizing LLMs to make methodological contributions toward addressing grand social challenges.17:T665,@inproceedings{xie2025predicting,
  title = {Predicting Patient Acuity in Tele-Triage Using Large Language Models: A Computational Design Science Approach},
  author = {Xie, Hetiao (Slim) and Namvar, Morteza and Akhlaghpour, Saeed and Staib, Andrew},
  booktitle = {Proceedings of 29th Pacific Asia Conference on Information Systems},
  year = {2025},
  abstract = {Recent advancements in artificial intelligence are revolutionizing healthcare. The development of AI models for predicting patient acuity in tele-triage shows promising potential for high-quality patient care and efficient healthcare systems. However, existing research has not explored how to achieve effective predictions using limited patient self-reported data. Therefore, we follow the computational design science approach to propose DAJoLoss, a novel dual-adapter architecture with a domain-based joint loss optimization method for fine-tuning large language models (LLMs). This computational artifact enables transfer learning from informative training-only data to improve prediction. Comprehensive evaluation results demonstrate that our artifact achieves at least a 5% improvement across all metrics compared to mainstream machine learning approaches in tele-triage research. This study not only provides insights into overcoming data availability limitations in tele-triage prediction but also contributes to information systems knowledge base on designing computational artifacts for optimizing LLMs to make methodological contributions toward addressing grand social challenges.},
  link = {https://aisel.aisnet.org/pacis2025/ishealthcare/ishealthcare/4/}
}18:T419,The spread of hate speech on social media and platforms’ reluctance to adopt the most prominent solutions necessitates more advanced methods for mitigating hate speech. Text detoxification (TD) represents a frontier approach by transforming text style to eliminate hateful content while preserving its original meaning. This approach shows the promising potential to remove online hateful content while avoiding risks to free speech. While emerging studies have begun exploring algorithmic advancements using large language models (LLMs) for TD, the overall understanding remains limited in guiding the development of effective TD systems. Therefore, our study rigorously reviewed 21 selected studies on TD to summarize existing knowledge and identify the challenges. We then propose a three-aspect framework with nine factors that effective TD systems should incorporate. Future research will extend this effort to develop a computational artifact for TD, with potential to significantly enhance this frontier approach for hate speech mitigation.19:T5be,@inproceedings{phan2025new,
  title = {The New Frontier in Mitigating Hate Speech: A Review to Guide Text Detoxification},
  author = {Phan, Thuy Linh (Isabella) and Xie, Hetiao (Slim) and Namvar, Morteza and Risius, Marten},
  booktitle = {Proceedings of 29th Pacific Asia Conference on Information Systems},
  year = {2025},
  abstract = {The spread of hate speech on social media and platforms’ reluctance to adopt the most prominent solutions necessitates more advanced methods for mitigating hate speech. Text detoxification (TD) represents a frontier approach by transforming text style to eliminate hateful content while preserving its original meaning. This approach shows the promising potential to remove online hateful content while avoiding risks to free speech. While emerging studies have begun exploring algorithmic advancements using large language models (LLMs) for TD, the overall understanding remains limited in guiding the development of effective TD systems. Therefore, our study rigorously reviewed 21 selected studies on TD to summarize existing knowledge and identify the challenges. We then propose a three-aspect framework with nine factors that effective TD systems should incorporate. Future research will extend this effort to develop a computational artifact for TD, with potential to significantly enhance this frontier approach for hate speech mitigation.},
  link = {https://aisel.aisnet.org/pacis2025/sm_digcollab/sm_digcollab/12/}
}1a:T407,Evaluating the effectiveness of hate speech detoxification is an emerging challenge, particularly as large language models (LLMs) become central to content moderation. While text detoxification (TD) presents a promising alternative to deletion or banning, current evaluation methods remain limited. Human evaluation is costly and inconsistent, and existing automatic metrics often fail to capture social sensitivity. We introduce SAFE-TD, a Structured Agentic Framework for Evaluation of TD, which simulates three agent roles to assess detoxified outputs from multiple perspectives. Our preliminary analysis reveals four outcome types and identifies a critical risk: the generation of implicit hate speech that appears neutral but retains harmful meaning. These findings expose under-explored trade-offs in TD and limitations in existing evaluation practices. SAFE-TD contributes a scalable, socially grounded approach to evaluating LLM-based TD, offering a foundation for more ethical and nuanced AI development for online safety.1b:T5c6,@inproceedings{phan2025same,
  title = {Same Same but Different: Evaluating Hate Speech Detoxification through an LLM-based Agentic Framework},
  author = {Phan, Thuy Linh (Isabella) and Boyce, James and Xie, Hetiao (Slim) and Namvar, Morteza and Risius, Marten},
  booktitle = {Proceedings of 46th International Conference on Information Systems},
  year = {2025},
  abstract = {Evaluating the effectiveness of hate speech detoxification is an emerging challenge, particularly as large language models (LLMs) become central to content moderation. While text detoxification (TD) presents a promising alternative to deletion or banning, current evaluation methods remain limited. Human evaluation is costly and inconsistent, and existing automatic metrics often fail to capture social sensitivity. We introduce SAFE-TD, a Structured Agentic Framework for Evaluation of TD, which simulates three agent roles to assess detoxified outputs from multiple perspectives. Our preliminary analysis reveals four outcome types and identifies a critical risk: the generation of implicit hate speech that appears neutral but retains harmful meaning. These findings expose under-explored trade-offs in TD and limitations in existing evaluation practices. SAFE-TD contributes a scalable, socially grounded approach to evaluating LLM-based TD, offering a foundation for more ethical and nuanced AI development for online safety.},
  link = {https://aisel.aisnet.org/icis2025/gen_ai/gen_ai/34/}
}1c:T478,The Australian housing market is one of the most dynamic and competitive in the world, consistently driven by the pursuit of the best possible selling outcomes. This study unpacks the context-specific sentiment embedded in property listing descriptions, introducing a novel approach to contextualised feature engineering and sentiment analysis that improves prediction of property selling outcomes. Drawing on domain knowledge, we construct three context-specific sentiments uniquely relevant to property sales: scarcity pressure, trust reassurance, and affordability concerns. Using advanced natural language processing techniques, we extract and quantify these features from listing texts. We demonstrate their effect by integrating them into machine learning models predicting property selling outcomes, where they significantly improve performance compared with general sentiment features. Beyond prediction, our findings show how contextualised sentiment provides a deeper understanding of the persuasive and affective signals within property listing descriptions, and offers practical insights into how descriptions shape market outcomes.1d:T5da,@inproceedings{xie2025reading,
  title = {Reading the Market: Unpacking Context-Specific Sentiment in Property Listing Descriptions},
  author = {Xie, Hetiao (Slim) and Ho, Yi-fang and Liu, Yutong and Boyce, James and Namvar, Morteza},
  booktitle = {Proceedings of 36th Australasian Conference on Information Systems},
  year = {2025},
  abstract = {The Australian housing market is one of the most dynamic and competitive in the world, consistently driven by the pursuit of the best possible selling outcomes. This study unpacks the context-specific sentiment embedded in property listing descriptions, introducing a novel approach to contextualised feature engineering and sentiment analysis that improves prediction of property selling outcomes. Drawing on domain knowledge, we construct three context-specific sentiments uniquely relevant to property sales: scarcity pressure, trust reassurance, and affordability concerns. Using advanced natural language processing techniques, we extract and quantify these features from listing texts. We demonstrate their effect by integrating them into machine learning models predicting property selling outcomes, where they significantly improve performance compared with general sentiment features. Beyond prediction, our findings show how contextualised sentiment provides a deeper understanding of the persuasive and affective signals within property listing descriptions, and offers practical insights into how descriptions shape market outcomes.}
}1e:T495,@inproceedings{xie2024navigating,
  title = {Navigating Implicit Hate Speech - A Scoping Review},
  author = {Xie, Hetiao (Slim) and Namvar, Morteza and Risius, Marten and Akhlaghpour, Saeed},
  booktitle = {Proceedings of 32nd European Conference on Information Systems},
  year = {2024},
  abstract = {The alarming growth of hate speech on social media platforms has caused serious consequences for individuals, online communities, and society. While the majority of related work focuses on explicit hate speech, research on implicit hate speech (IHS) is still in its infancy. IHS is a more subtle form of hate that poses considerable challenges for victims, platforms, regulators, and society. To address this gap, we propose a scoping review of IHS to investigate its current state of research, with an emphasis on summarizing its phenotypes, detection challenges, and state-of-the-art detection methods. Our work aims to build a foundation for future studies and pave the way for in-depth research on the characteristics of IHS, as well as potential agendas for countering it.},
  link = {https://aisel.aisnet.org/ecis2024/track24_socialmedia/track24_socialmedia/8/}
}1f:T4df,Extremists exploit social media platforms to spread hate against minority groups based on protected attributes such as gender, religion, and ethnicity. Platforms and researchers have been actively developing AI tools to detect and remove such hate speech. However, extremists employ various forms of implicit hate speech (IHS) to evade AI detection systems. IHS spreads hateful messages using subtle expressions and complex contextual semantic relationships instead of explicit abusive words, bringing challenges to automatic detection algorithms. Common forms of IHS include dog whistles, coded language, humorous hate speech, and implicit dehumanisation. Moreover, the forms and expressions of IHS evolve rapidly with societal controversies (e.g., regional wars). Identifying and tracking such changes in IHS is crucial for platforms trying to counter them. In this Insight, we report and analyse “Substitution” as a new form of IHS. Recently, we observed extremists using “Substitution” by propagating hateful rhetoric against a target group (e.g., Jews) while explicitly referencing another label group (e.g., Chinese). We show that Substitution not only effectively spreads hate but also exacerbates engagement and obscures detection.20:T6a3,@inproceedings{xie2024substitution,
  title = {"Substitution": Extremists' New Form of Implicit Hate Speech to Avoid Detection},
  author = {Xie, Hetiao (Slim) and Risius, Marten and Namvar, Morteza and Akhlaghpour, Saeed},
  booktitle = {Global Network on Extremism and Technology (GNET)},
  year = {2024},
  abstract = {Extremists exploit social media platforms to spread hate against minority groups based on protected attributes such as gender, religion, and ethnicity. Platforms and researchers have been actively developing AI tools to detect and remove such hate speech. However, extremists employ various forms of implicit hate speech (IHS) to evade AI detection systems.  IHS spreads hateful messages using subtle expressions and complex contextual semantic relationships instead of explicit abusive words, bringing challenges to automatic detection algorithms. Common forms of IHS include dog whistles, coded language, humorous hate speech, and implicit dehumanisation. Moreover, the forms and expressions of IHS evolve rapidly with societal controversies (e.g., regional wars). Identifying and tracking such changes in IHS is crucial for platforms trying to counter them. In this Insight, we report and analyse “Substitution” as a new form of IHS. Recently, we observed extremists using “Substitution” by propagating hateful rhetoric against a target group (e.g., Jews) while explicitly referencing another label group (e.g., Chinese). We show that Substitution not only effectively spreads hate but also exacerbates engagement and obscures detection.},
  link = {https://gnet-research.org/2024/06/24/substitution-extremists-new-form-of-implicit-hate-speech-to-avoid-detection/}
}21:T432,Hate speech on social media platforms has severe impacts on individuals, online communities, and society. Platforms are criticized for shirking their responsibilities to effectively moderate hate speech on their platforms. However, Various challenges, including implicit expressions, complicate the task of detecting hate speech. Consequently, developing and tuning algorithms for improving the automated detection of hate speech has emerged as a crucial research topic. This paper aims to contribute to this rapidly emerging field by outlining how the adoption of natural language processing and machine learning technologies has helped hate speech detection, delving into the latest mainstream detection techniques and their performance, and offering a comprehensive review of the literature on hate speech detection online including the notable challenges and respective mitigating efforts. This paper proposes the integration of interdisciplinary perspectives into deep learning models to enhance the generalization of models, providing a new agenda for future research.22:T560,@inproceedings{xie2023review,
  title = {A Review of Hate Speech Detection: Challenges and Innovations},
  author = {Xie, Hetiao (Slim) and Namvar, Morteza and Risius, Marten},
  booktitle = {Digit 2023 Proceedings},
  year = {2023},
  abstract = {Hate speech on social media platforms has severe impacts on individuals, online communities, and society. Platforms are criticized for shirking their responsibilities to effectively moderate hate speech on their platforms. However, Various challenges, including implicit expressions, complicate the task of detecting hate speech. Consequently, developing and tuning algorithms for improving the automated detection of hate speech has emerged as a crucial research topic. This paper aims to contribute to this rapidly emerging field by outlining how the adoption of natural language processing and machine learning technologies has helped hate speech detection, delving into the latest mainstream detection techniques and their performance, and offering a comprehensive review of the literature on hate speech detection online including the notable challenges and respective mitigating efforts. This paper proposes the integration of interdisciplinary perspectives into deep learning models to enhance the generalization of models, providing a new agenda for future research.},
  link = {https://aisel.aisnet.org/digit2023/15/}
}7:["$","div",null,{"className":"max-w-4xl mx-auto px-4 sm:px-6 lg:px-8 py-12","children":[["$","$L15",null,{"config":{"type":"publication","title":"Publications","description":"A collection of my published research work.","source":"publications.bib"},"publications":[{"id":"xie2025predicting","title":"Predicting Patient Acuity in Tele-Triage Using Large Language Models: A Computational Design Science Approach","authors":[{"name":"Hetiao (Slim) Xie","isHighlighted":true,"isCorresponding":false,"isCoAuthor":false},{"name":"Morteza Namvar","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Saeed Akhlaghpour","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Andrew Staib","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false}],"year":2025,"type":"conference","status":"published","tags":[],"keywords":"$7:props:children:0:props:publications:0:tags","researchArea":"machine-learning","journal":"","conference":"Proceedings of 29th Pacific Asia Conference on Information Systems","abstract":"$16","description":"","selected":false,"preview":"PACIS2025-TT.png","bibtex":"$17"},{"id":"phan2025new","title":"The New Frontier in Mitigating Hate Speech: A Review to Guide Text Detoxification","authors":[{"name":"Thuy Linh (Isabella) Phan","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Hetiao (Slim) Xie","isHighlighted":true,"isCorresponding":false,"isCoAuthor":false},{"name":"Morteza Namvar","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Marten Risius","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false}],"year":2025,"type":"conference","status":"published","tags":[],"keywords":"$7:props:children:0:props:publications:1:tags","researchArea":"machine-learning","journal":"","conference":"Proceedings of 29th Pacific Asia Conference on Information Systems","abstract":"$18","description":"","selected":false,"preview":"PACIS2025-TD.jpg","bibtex":"$19"},{"id":"phan2025same","title":"Same Same but Different: Evaluating Hate Speech Detoxification through an LLM-based Agentic Framework","authors":[{"name":"Thuy Linh (Isabella) Phan","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"James Boyce","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Hetiao (Slim) Xie","isHighlighted":true,"isCorresponding":false,"isCoAuthor":false},{"name":"Morteza Namvar","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Marten Risius","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false}],"year":2025,"type":"conference","status":"published","tags":[],"keywords":"$7:props:children:0:props:publications:2:tags","researchArea":"machine-learning","journal":"","conference":"Proceedings of 46th International Conference on Information Systems","abstract":"$1a","description":"","selected":false,"preview":"ICIS2025.png","bibtex":"$1b"},{"id":"xie2025reading","title":"Reading the Market: Unpacking Context-Specific Sentiment in Property Listing Descriptions","authors":[{"name":"Hetiao (Slim) Xie","isHighlighted":true,"isCorresponding":false,"isCoAuthor":false},{"name":"Yi-fang Ho","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Yutong Liu","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"James Boyce","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Morteza Namvar","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false}],"year":2025,"type":"conference","status":"published","tags":[],"keywords":"$7:props:children:0:props:publications:3:tags","researchArea":"machine-learning","journal":"","conference":"Proceedings of 36th Australasian Conference on Information Systems","abstract":"$1c","description":"","selected":false,"preview":"ACIS2025.PNG","bibtex":"$1d"},{"id":"xie2024navigating","title":"Navigating Implicit Hate Speech - A Scoping Review","authors":[{"name":"Hetiao (Slim) Xie","isHighlighted":true,"isCorresponding":false,"isCoAuthor":false},{"name":"Morteza Namvar","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Marten Risius","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Saeed Akhlaghpour","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false}],"year":2024,"type":"conference","status":"published","tags":[],"keywords":"$7:props:children:0:props:publications:4:tags","researchArea":"machine-learning","journal":"","conference":"Proceedings of 32nd European Conference on Information Systems","abstract":"The alarming growth of hate speech on social media platforms has caused serious consequences for individuals, online communities, and society. While the majority of related work focuses on explicit hate speech, research on implicit hate speech (IHS) is still in its infancy. IHS is a more subtle form of hate that poses considerable challenges for victims, platforms, regulators, and society. To address this gap, we propose a scoping review of IHS to investigate its current state of research, with an emphasis on summarizing its phenotypes, detection challenges, and state-of-the-art detection methods. Our work aims to build a foundation for future studies and pave the way for in-depth research on the characteristics of IHS, as well as potential agendas for countering it.","description":"","selected":false,"bibtex":"$1e"},{"id":"xie2024substitution","title":"Substitution\": Extremists' New Form of Implicit Hate Speech to Avoid Detection","authors":[{"name":"Hetiao (Slim) Xie","isHighlighted":true,"isCorresponding":false,"isCoAuthor":false},{"name":"Marten Risius","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Morteza Namvar","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Saeed Akhlaghpour","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false}],"year":2024,"type":"conference","status":"published","tags":[],"keywords":"$7:props:children:0:props:publications:5:tags","researchArea":"machine-learning","journal":"","conference":"Global Network on Extremism and Technology (GNET)","abstract":"$1f","description":"","selected":false,"preview":"GNET.png","bibtex":"$20"},{"id":"xie2023review","title":"A Review of Hate Speech Detection: Challenges and Innovations","authors":[{"name":"Hetiao (Slim) Xie","isHighlighted":true,"isCorresponding":false,"isCoAuthor":false},{"name":"Morteza Namvar","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Marten Risius","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false}],"year":2023,"type":"conference","status":"published","tags":[],"keywords":"$7:props:children:0:props:publications:6:tags","researchArea":"machine-learning","journal":"","conference":"Digit 2023 Proceedings","abstract":"$21","description":"","selected":false,"bibtex":"$22"}]}],false,false]}]
c:null
10:[["$","meta","0",{"charSet":"utf-8"}],["$","meta","1",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
b:null
14:{"metadata":[["$","title","0",{"children":"Publications | Slim"}],["$","meta","1",{"name":"description","content":"A collection of my published research work."}],["$","meta","2",{"name":"author","content":"Hetiao (Slim) Xie"}],["$","meta","3",{"name":"keywords","content":"Hetiao (Slim) Xie,PhD,Research,University of Queensland"}],["$","meta","4",{"name":"creator","content":"Hetiao (Slim) Xie"}],["$","meta","5",{"name":"publisher","content":"Hetiao (Slim) Xie"}],["$","meta","6",{"property":"og:title","content":"Slim"}],["$","meta","7",{"property":"og:description","content":"PhD student at The University of Queensland"}],["$","meta","8",{"property":"og:site_name","content":"Hetiao (Slim) Xie's Academic Website"}],["$","meta","9",{"property":"og:locale","content":"en_US"}],["$","meta","10",{"property":"og:type","content":"website"}],["$","meta","11",{"name":"twitter:card","content":"summary"}],["$","meta","12",{"name":"twitter:title","content":"Slim"}],["$","meta","13",{"name":"twitter:description","content":"PhD student at The University of Queensland"}],["$","link","14",{"rel":"icon","href":"/favicon.svg"}]],"error":null,"digest":"$undefined"}
e:{"metadata":"$14:metadata","error":null,"digest":"$undefined"}
